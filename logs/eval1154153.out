Results already exist at /lustre/fswork/projects/rech/awr/uof65ov/kv_cache_comp/kvpress/evaluation/results/loogle__shortdep_qa__meta-llama--Llama-3.1-8B-Instruct__knorm__0.75.csv
Using the latest cached version of the dataset since simonjegou/loogle couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'shortdep_qa' at /lustre/fsn1/projects/rech/awr/uof65ov/hf_cache/simonjegou___loogle/shortdep_qa/0.0.0/6e3eaf28d24ce34933170c85de36be2448d0d2a7 (last modified on Mon Nov 25 15:20:25 2024).
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  6.75it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  6.97it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  6.78it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00,  7.61it/s]
srun: Job step aborted: Waiting up to 62 seconds for job step to finish.
slurmstepd: error: *** JOB 1154153 ON jean-zay-iam52 CANCELLED AT 2024-12-04T21:21:48 ***
slurmstepd: error: *** STEP 1154153.0 ON jean-zay-iam52 CANCELLED AT 2024-12-04T21:21:48 ***
