Using the latest cached version of the dataset since simonjegou/loogle couldn't be found on the Hugging Face Hub (offline mode is enabled).
Found the latest cached dataset configuration 'longdep_qa' at /lustre/fsn1/projects/rech/awr/uof65ov/hf_cache/simonjegou___loogle/longdep_qa/0.0.0/6e3eaf28d24ce34933170c85de36be2448d0d2a7 (last modified on Mon Nov 25 15:20:17 2024).
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  9.42it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00, 10.50it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 10.86it/s]
  0%|          | 0/140 [00:00<?, ?it/s]The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.
  1%|          | 1/140 [00:16<37:51, 16.34s/it]  1%|▏         | 2/140 [00:31<35:37, 15.49s/it]  2%|▏         | 3/140 [00:48<37:15, 16.32s/it]  3%|▎         | 4/140 [01:08<40:06, 17.70s/it]  4%|▎         | 5/140 [01:25<39:14, 17.44s/it]  4%|▍         | 6/140 [02:10<59:52, 26.81s/it]  5%|▌         | 7/140 [03:36<1:42:38, 46.30s/it]  6%|▌         | 8/140 [03:57<1:23:42, 38.05s/it]  6%|▋         | 9/140 [04:15<1:09:31, 31.84s/it]  7%|▋         | 10/140 [04:24<54:03, 24.95s/it] You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  8%|▊         | 11/140 [04:44<50:09, 23.33s/it]  9%|▊         | 12/140 [05:13<53:28, 25.06s/it]  9%|▉         | 13/140 [05:26<45:30, 21.50s/it] 10%|█         | 14/140 [05:42<41:29, 19.76s/it] 11%|█         | 15/140 [06:14<48:38, 23.35s/it] 11%|█▏        | 16/140 [06:56<59:56, 29.01s/it] 12%|█▏        | 17/140 [07:17<54:36, 26.64s/it] 13%|█▎        | 18/140 [07:37<49:48, 24.50s/it] 14%|█▎        | 19/140 [08:11<55:27, 27.50s/it] 14%|█▍        | 20/140 [08:22<45:15, 22.63s/it] 15%|█▌        | 21/140 [08:44<44:05, 22.23s/it] 16%|█▌        | 22/140 [09:29<57:37, 29.30s/it] 16%|█▋        | 23/140 [09:52<53:30, 27.44s/it] 17%|█▋        | 24/140 [10:09<46:57, 24.29s/it] 18%|█▊        | 25/140 [10:15<36:03, 18.82s/it] 19%|█▊        | 26/140 [10:32<34:43, 18.27s/it] 19%|█▉        | 27/140 [11:01<40:11, 21.34s/it] 20%|██        | 28/140 [11:11<33:33, 17.98s/it] 21%|██        | 29/140 [11:31<34:09, 18.47s/it] 21%|██▏       | 30/140 [11:37<27:11, 14.83s/it] 22%|██▏       | 31/140 [11:52<27:03, 14.89s/it] 23%|██▎       | 32/140 [12:12<29:23, 16.33s/it] 24%|██▎       | 33/140 [12:57<44:20, 24.87s/it] 24%|██▍       | 34/140 [13:29<47:47, 27.06s/it] 25%|██▌       | 35/140 [13:46<42:27, 24.26s/it] 26%|██▌       | 36/140 [13:58<35:22, 20.41s/it] 26%|██▋       | 37/140 [14:35<43:50, 25.54s/it] 27%|██▋       | 38/140 [14:56<41:04, 24.16s/it] 28%|██▊       | 39/140 [15:03<31:38, 18.80s/it] 29%|██▊       | 40/140 [15:23<32:04, 19.24s/it] 29%|██▉       | 41/140 [16:10<45:34, 27.62s/it] 30%|███       | 42/140 [16:23<37:47, 23.14s/it] 31%|███       | 43/140 [16:55<41:46, 25.84s/it] 31%|███▏      | 44/140 [17:33<47:23, 29.62s/it] 32%|███▏      | 45/140 [17:45<38:33, 24.35s/it] 33%|███▎      | 46/140 [18:05<35:54, 22.92s/it] 34%|███▎      | 47/140 [18:27<35:17, 22.77s/it] 34%|███▍      | 48/140 [18:38<29:30, 19.25s/it] 35%|███▌      | 49/140 [18:57<28:40, 18.91s/it] 36%|███▌      | 50/140 [19:25<32:27, 21.63s/it] 36%|███▋      | 51/140 [19:40<29:22, 19.80s/it] 37%|███▋      | 52/140 [19:47<23:25, 15.97s/it] 38%|███▊      | 53/140 [20:19<29:57, 20.66s/it] 39%|███▊      | 54/140 [20:27<24:09, 16.86s/it] 39%|███▉      | 55/140 [20:35<20:02, 14.15s/it] 40%|████      | 56/140 [21:23<34:15, 24.47s/it] 41%|████      | 57/140 [21:29<26:04, 18.85s/it] 41%|████▏     | 58/140 [21:51<27:07, 19.85s/it] 42%|████▏     | 59/140 [22:28<33:48, 25.04s/it] 43%|████▎     | 60/140 [22:54<33:43, 25.29s/it] 44%|████▎     | 61/140 [23:23<34:39, 26.32s/it] 44%|████▍     | 62/140 [23:32<27:24, 21.08s/it] 45%|████▌     | 63/140 [23:51<26:19, 20.51s/it] 46%|████▌     | 64/140 [24:17<28:09, 22.23s/it] 46%|████▋     | 65/140 [24:44<29:35, 23.67s/it] 47%|████▋     | 66/140 [25:00<26:23, 21.40s/it] 48%|████▊     | 67/140 [25:17<24:18, 19.99s/it] 49%|████▊     | 68/140 [25:34<22:54, 19.09s/it] 49%|████▉     | 69/140 [25:41<18:18, 15.47s/it] 50%|█████     | 70/140 [25:56<17:48, 15.27s/it] 51%|█████     | 71/140 [26:25<22:25, 19.50s/it] 51%|█████▏    | 72/140 [26:32<17:58, 15.87s/it] 52%|█████▏    | 73/140 [26:47<17:10, 15.38s/it] 53%|█████▎    | 74/140 [26:59<15:45, 14.32s/it] 54%|█████▎    | 75/140 [27:07<13:43, 12.67s/it] 54%|█████▍    | 76/140 [27:23<14:22, 13.47s/it] 55%|█████▌    | 77/140 [27:32<12:56, 12.32s/it] 56%|█████▌    | 78/140 [27:48<13:44, 13.30s/it] 56%|█████▋    | 79/140 [28:05<14:35, 14.34s/it] 57%|█████▋    | 80/140 [28:19<14:14, 14.25s/it] 58%|█████▊    | 81/140 [28:30<13:12, 13.44s/it] 59%|█████▊    | 82/140 [28:45<13:20, 13.80s/it] 59%|█████▉    | 83/140 [28:59<13:15, 13.95s/it] 60%|██████    | 84/140 [29:18<14:20, 15.37s/it] 61%|██████    | 85/140 [29:40<15:53, 17.34s/it] 61%|██████▏   | 86/140 [29:53<14:33, 16.17s/it] 62%|██████▏   | 87/140 [30:29<19:27, 22.03s/it] 63%|██████▎   | 88/140 [30:42<16:38, 19.20s/it] 64%|██████▎   | 89/140 [31:01<16:16, 19.15s/it] 64%|██████▍   | 90/140 [31:20<16:02, 19.25s/it] 65%|██████▌   | 91/140 [31:40<15:50, 19.41s/it] 66%|██████▌   | 92/140 [31:52<13:46, 17.21s/it] 66%|██████▋   | 93/140 [32:15<14:55, 19.05s/it] 67%|██████▋   | 94/140 [32:29<13:23, 17.46s/it] 68%|██████▊   | 95/140 [32:54<14:48, 19.73s/it] 69%|██████▊   | 96/140 [33:05<12:27, 17.00s/it] 69%|██████▉   | 97/140 [33:33<14:34, 20.34s/it] 70%|███████   | 98/140 [33:47<12:59, 18.56s/it] 71%|███████   | 99/140 [34:02<11:49, 17.30s/it] 71%|███████▏  | 100/140 [34:36<15:00, 22.50s/it] 72%|███████▏  | 101/140 [34:59<14:40, 22.57s/it] 73%|███████▎  | 102/140 [35:19<13:52, 21.90s/it] 74%|███████▎  | 103/140 [35:45<14:12, 23.05s/it] 74%|███████▍  | 104/140 [35:56<11:43, 19.55s/it] 75%|███████▌  | 105/140 [36:34<14:30, 24.87s/it] 76%|███████▌  | 106/140 [36:59<14:08, 24.95s/it] 76%|███████▋  | 107/140 [37:14<12:11, 22.16s/it] 77%|███████▋  | 108/140 [37:23<09:37, 18.04s/it] 78%|███████▊  | 109/140 [37:36<08:32, 16.55s/it] 79%|███████▊  | 110/140 [38:10<10:55, 21.86s/it] 79%|███████▉  | 111/140 [38:24<09:20, 19.32s/it] 80%|████████  | 112/140 [38:33<07:35, 16.27s/it] 81%|████████  | 113/140 [39:05<09:27, 21.01s/it] 81%|████████▏ | 114/140 [39:16<07:49, 18.05s/it] 82%|████████▏ | 115/140 [39:27<06:39, 15.97s/it] 83%|████████▎ | 116/140 [39:41<06:09, 15.41s/it] 84%|████████▎ | 117/140 [40:09<07:19, 19.11s/it] 84%|████████▍ | 118/140 [40:27<06:50, 18.67s/it] 85%|████████▌ | 119/140 [41:00<08:03, 23.00s/it] 86%|████████▌ | 120/140 [41:17<07:08, 21.40s/it] 86%|████████▋ | 121/140 [41:33<06:14, 19.69s/it] 87%|████████▋ | 122/140 [41:42<04:55, 16.40s/it] 88%|████████▊ | 123/140 [41:54<04:18, 15.19s/it] 89%|████████▊ | 124/140 [42:10<04:07, 15.46s/it] 89%|████████▉ | 125/140 [42:23<03:37, 14.52s/it] 90%|█████████ | 126/140 [42:45<03:57, 16.93s/it] 91%|█████████ | 127/140 [43:01<03:37, 16.73s/it] 91%|█████████▏| 128/140 [43:19<03:25, 17.12s/it] 92%|█████████▏| 129/140 [43:31<02:48, 15.34s/it] 93%|█████████▎| 130/140 [43:39<02:12, 13.24s/it] 94%|█████████▎| 131/140 [43:57<02:13, 14.79s/it] 94%|█████████▍| 132/140 [44:08<01:48, 13.60s/it] 95%|█████████▌| 133/140 [44:21<01:33, 13.35s/it] 96%|█████████▌| 134/140 [44:46<01:41, 16.88s/it] 96%|█████████▋| 135/140 [44:59<01:18, 15.79s/it] 97%|█████████▋| 136/140 [45:15<01:03, 15.75s/it] 98%|█████████▊| 137/140 [45:54<01:08, 22.76s/it] 99%|█████████▊| 138/140 [46:12<00:42, 21.32s/it] 99%|█████████▉| 139/140 [46:37<00:22, 22.33s/it]100%|██████████| 140/140 [47:03<00:00, 23.55s/it]100%|██████████| 140/140 [47:03<00:00, 20.17s/it]
[nltk_data] Error loading wordnet: <urlopen error [Errno 101] Network
[nltk_data]     is unreachable>
/lustre/fswork/projects/rech/awr/uof65ov/kv_cache_comp/venv/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: 
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/lustre/fswork/projects/rech/awr/uof65ov/kv_cache_comp/venv/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/lustre/fswork/projects/rech/awr/uof65ov/kv_cache_comp/venv/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
{'longdep_qa': {'bleu1': 0.05638317852746695, 'bleu4': 0.0052737514315798085, 'rouge-1': 0.21757745733032183, 'rouge-2': 0.05586966511702801, 'rouge-l': 0.20716999248244336, 'meteor': 0.08262344834338317, 'bert': 0.830691397190094}}
